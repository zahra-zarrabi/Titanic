{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPblss1StxSJi9x45Bi6JGW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zahra-zarrabi/Titanic/blob/master/MachineLearning_Titanic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD1hLqzn8SlO"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "gfL-mlTBgFeU",
        "outputId": "d204465d-3ac9-4181-f7b4-e825e0be818c"
      },
      "source": [
        "train_data = pd.read_csv('/content/train.csv')\n",
        "\n",
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "0            1         0       3  ...   7.2500   NaN         S\n",
              "1            2         1       1  ...  71.2833   C85         C\n",
              "2            3         1       3  ...   7.9250   NaN         S\n",
              "3            4         1       1  ...  53.1000  C123         S\n",
              "4            5         0       3  ...   8.0500   NaN         S\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrquL6cbgoiz"
      },
      "source": [
        "#process\n",
        "train_data = train_data.replace(['female','male'],[0, 1])\n",
        "train_data = train_data.replace(['S','C','Q'],[0, 1, 2])\n",
        "train_data=train_data.fillna(0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfiHKofkh5DX"
      },
      "source": [
        "X_train = train_data[['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']]\n",
        "Y_train = train_data[['Survived']]\n",
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3l-K4KuiAHF"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Dense(7,activation='relu'),\n",
        "                                    tf.keras.layers.Dense(10,activation='relu'),\n",
        "                                    tf.keras.layers.Dense(7,activation='sigmoid'),\n",
        "                                    # tf.keras.layers.Dense(32,activation='relu'),\n",
        "                                    tf.keras.layers.Dense(2,activation='sigmoid')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSK4YBf4iI-P"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adamax(learning_rate=0.001),\n",
        "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmZNg93DiLLn",
        "outputId": "697a8e06-17c3-4156-b9a7-0cc1cf60e9c5"
      },
      "source": [
        "output=model.fit(X_train,Y_train,epochs=600)\n",
        "model.save('/content/model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/600\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.7548 - accuracy: 0.6162\n",
            "Epoch 2/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.6162\n",
            "Epoch 3/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6605 - accuracy: 0.6162\n",
            "Epoch 4/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6513 - accuracy: 0.6162\n",
            "Epoch 5/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6162\n",
            "Epoch 6/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6430 - accuracy: 0.6162\n",
            "Epoch 7/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6399 - accuracy: 0.6162\n",
            "Epoch 8/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6367 - accuracy: 0.6162\n",
            "Epoch 9/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6337 - accuracy: 0.6162\n",
            "Epoch 10/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6311 - accuracy: 0.6162\n",
            "Epoch 11/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6289 - accuracy: 0.6162\n",
            "Epoch 12/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6272 - accuracy: 0.6162\n",
            "Epoch 13/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6252 - accuracy: 0.6162\n",
            "Epoch 14/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6236 - accuracy: 0.6453\n",
            "Epoch 15/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6222 - accuracy: 0.6655\n",
            "Epoch 16/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6208 - accuracy: 0.6734\n",
            "Epoch 17/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6197 - accuracy: 0.6835\n",
            "Epoch 18/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6184 - accuracy: 0.6869\n",
            "Epoch 19/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6175 - accuracy: 0.6869\n",
            "Epoch 20/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6161 - accuracy: 0.6891\n",
            "Epoch 21/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6154 - accuracy: 0.6869\n",
            "Epoch 22/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6144 - accuracy: 0.6869\n",
            "Epoch 23/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6132 - accuracy: 0.6846\n",
            "Epoch 24/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.6123 - accuracy: 0.6835\n",
            "Epoch 25/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6117 - accuracy: 0.6846\n",
            "Epoch 26/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6106 - accuracy: 0.6846\n",
            "Epoch 27/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.6097 - accuracy: 0.6846\n",
            "Epoch 28/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6090 - accuracy: 0.6857\n",
            "Epoch 29/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6083 - accuracy: 0.6902\n",
            "Epoch 30/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6075 - accuracy: 0.6891\n",
            "Epoch 31/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.6070 - accuracy: 0.6869\n",
            "Epoch 32/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6063 - accuracy: 0.6914\n",
            "Epoch 33/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6055 - accuracy: 0.6880\n",
            "Epoch 34/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.6048 - accuracy: 0.6880\n",
            "Epoch 35/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6043 - accuracy: 0.6880\n",
            "Epoch 36/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6036 - accuracy: 0.6891\n",
            "Epoch 37/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6030 - accuracy: 0.6880\n",
            "Epoch 38/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6024 - accuracy: 0.6902\n",
            "Epoch 39/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6020 - accuracy: 0.6902\n",
            "Epoch 40/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6011 - accuracy: 0.6936\n",
            "Epoch 41/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6009 - accuracy: 0.6902\n",
            "Epoch 42/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5995 - accuracy: 0.6914\n",
            "Epoch 43/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5993 - accuracy: 0.6880\n",
            "Epoch 44/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5986 - accuracy: 0.6880\n",
            "Epoch 45/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5981 - accuracy: 0.6902\n",
            "Epoch 46/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5974 - accuracy: 0.6947\n",
            "Epoch 47/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5968 - accuracy: 0.6880\n",
            "Epoch 48/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5960 - accuracy: 0.6902\n",
            "Epoch 49/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5953 - accuracy: 0.6925\n",
            "Epoch 50/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5952 - accuracy: 0.6891\n",
            "Epoch 51/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5938 - accuracy: 0.6891\n",
            "Epoch 52/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5929 - accuracy: 0.6936\n",
            "Epoch 53/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5932 - accuracy: 0.6947\n",
            "Epoch 54/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5914 - accuracy: 0.6914\n",
            "Epoch 55/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5910 - accuracy: 0.6947\n",
            "Epoch 56/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5904 - accuracy: 0.6958\n",
            "Epoch 57/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5897 - accuracy: 0.6958\n",
            "Epoch 58/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5893 - accuracy: 0.6936\n",
            "Epoch 59/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5891 - accuracy: 0.6925\n",
            "Epoch 60/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5879 - accuracy: 0.6992\n",
            "Epoch 61/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5880 - accuracy: 0.6992\n",
            "Epoch 62/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5866 - accuracy: 0.7015\n",
            "Epoch 63/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5861 - accuracy: 0.7037\n",
            "Epoch 64/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.6958\n",
            "Epoch 65/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.6947\n",
            "Epoch 66/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5837 - accuracy: 0.6992\n",
            "Epoch 67/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.7003\n",
            "Epoch 68/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5826 - accuracy: 0.6970\n",
            "Epoch 69/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.7015\n",
            "Epoch 70/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.7003\n",
            "Epoch 71/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5801 - accuracy: 0.7015\n",
            "Epoch 72/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.7003\n",
            "Epoch 73/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5790 - accuracy: 0.7003\n",
            "Epoch 74/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5778 - accuracy: 0.7015\n",
            "Epoch 75/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5769 - accuracy: 0.7015\n",
            "Epoch 76/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5766 - accuracy: 0.7003\n",
            "Epoch 77/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5757 - accuracy: 0.7015\n",
            "Epoch 78/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5746 - accuracy: 0.6958\n",
            "Epoch 79/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5740 - accuracy: 0.7026\n",
            "Epoch 80/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5733 - accuracy: 0.7026\n",
            "Epoch 81/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5726 - accuracy: 0.7003\n",
            "Epoch 82/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5718 - accuracy: 0.7003\n",
            "Epoch 83/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5710 - accuracy: 0.7003\n",
            "Epoch 84/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5702 - accuracy: 0.7003\n",
            "Epoch 85/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5697 - accuracy: 0.7003\n",
            "Epoch 86/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5688 - accuracy: 0.7003\n",
            "Epoch 87/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5687 - accuracy: 0.7048\n",
            "Epoch 88/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5671 - accuracy: 0.7026\n",
            "Epoch 89/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5666 - accuracy: 0.7037\n",
            "Epoch 90/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5656 - accuracy: 0.7037\n",
            "Epoch 91/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5646 - accuracy: 0.7026\n",
            "Epoch 92/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5637 - accuracy: 0.7059\n",
            "Epoch 93/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5628 - accuracy: 0.7082\n",
            "Epoch 94/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5619 - accuracy: 0.7104\n",
            "Epoch 95/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5611 - accuracy: 0.7093\n",
            "Epoch 96/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5602 - accuracy: 0.7093\n",
            "Epoch 97/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5592 - accuracy: 0.7116\n",
            "Epoch 98/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5593 - accuracy: 0.7104\n",
            "Epoch 99/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.7116\n",
            "Epoch 100/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.7160\n",
            "Epoch 101/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.7138\n",
            "Epoch 102/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5549 - accuracy: 0.7104\n",
            "Epoch 103/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5538 - accuracy: 0.7104\n",
            "Epoch 104/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5536 - accuracy: 0.7127\n",
            "Epoch 105/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5517 - accuracy: 0.7160\n",
            "Epoch 106/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7183\n",
            "Epoch 107/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7194\n",
            "Epoch 108/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7160\n",
            "Epoch 109/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.7172\n",
            "Epoch 110/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.7172\n",
            "Epoch 111/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7138\n",
            "Epoch 112/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7149\n",
            "Epoch 113/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7160\n",
            "Epoch 114/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5449 - accuracy: 0.7239\n",
            "Epoch 115/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.7149\n",
            "Epoch 116/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5432 - accuracy: 0.7250\n",
            "Epoch 117/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.7306\n",
            "Epoch 118/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.7273\n",
            "Epoch 119/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7262\n",
            "Epoch 120/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5399 - accuracy: 0.7306\n",
            "Epoch 121/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5389 - accuracy: 0.7306\n",
            "Epoch 122/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5382 - accuracy: 0.7284\n",
            "Epoch 123/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5374 - accuracy: 0.7284\n",
            "Epoch 124/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5366 - accuracy: 0.7284\n",
            "Epoch 125/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.7284\n",
            "Epoch 126/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.7273\n",
            "Epoch 127/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.7295\n",
            "Epoch 128/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.7306\n",
            "Epoch 129/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7306\n",
            "Epoch 130/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5313 - accuracy: 0.7295\n",
            "Epoch 131/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5304 - accuracy: 0.7295\n",
            "Epoch 132/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7329\n",
            "Epoch 133/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5286 - accuracy: 0.7318\n",
            "Epoch 134/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.7340\n",
            "Epoch 135/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7306\n",
            "Epoch 136/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7329\n",
            "Epoch 137/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5252 - accuracy: 0.7351\n",
            "Epoch 138/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.7363\n",
            "Epoch 139/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5234 - accuracy: 0.7374\n",
            "Epoch 140/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7396\n",
            "Epoch 141/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5224 - accuracy: 0.7441\n",
            "Epoch 142/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7374\n",
            "Epoch 143/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5205 - accuracy: 0.7407\n",
            "Epoch 144/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5194 - accuracy: 0.7419\n",
            "Epoch 145/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5191 - accuracy: 0.7430\n",
            "Epoch 146/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5186 - accuracy: 0.7385\n",
            "Epoch 147/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7374\n",
            "Epoch 148/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5177 - accuracy: 0.7430\n",
            "Epoch 149/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5166 - accuracy: 0.7441\n",
            "Epoch 150/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7441\n",
            "Epoch 151/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7464\n",
            "Epoch 152/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5138 - accuracy: 0.7441\n",
            "Epoch 153/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7419\n",
            "Epoch 154/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7508\n",
            "Epoch 155/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5119 - accuracy: 0.7396\n",
            "Epoch 156/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5106 - accuracy: 0.7430\n",
            "Epoch 157/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.7475\n",
            "Epoch 158/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5093 - accuracy: 0.7475\n",
            "Epoch 159/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5082 - accuracy: 0.7520\n",
            "Epoch 160/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7531\n",
            "Epoch 161/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5065 - accuracy: 0.7497\n",
            "Epoch 162/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5057 - accuracy: 0.7520\n",
            "Epoch 163/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5054 - accuracy: 0.7508\n",
            "Epoch 164/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5045 - accuracy: 0.7553\n",
            "Epoch 165/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7576\n",
            "Epoch 166/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7576\n",
            "Epoch 167/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7598\n",
            "Epoch 168/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7587\n",
            "Epoch 169/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5012 - accuracy: 0.7587\n",
            "Epoch 170/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5007 - accuracy: 0.7587\n",
            "Epoch 171/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5002 - accuracy: 0.7598\n",
            "Epoch 172/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7598\n",
            "Epoch 173/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.7598\n",
            "Epoch 174/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4986 - accuracy: 0.7632\n",
            "Epoch 175/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7621\n",
            "Epoch 176/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4973 - accuracy: 0.7621\n",
            "Epoch 177/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.7666\n",
            "Epoch 178/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4960 - accuracy: 0.7677\n",
            "Epoch 179/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4952 - accuracy: 0.7710\n",
            "Epoch 180/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4951 - accuracy: 0.7666\n",
            "Epoch 181/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4946 - accuracy: 0.7722\n",
            "Epoch 182/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4935 - accuracy: 0.7688\n",
            "Epoch 183/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4938 - accuracy: 0.7710\n",
            "Epoch 184/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4929 - accuracy: 0.7778\n",
            "Epoch 185/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.7789\n",
            "Epoch 186/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4913 - accuracy: 0.7733\n",
            "Epoch 187/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4908 - accuracy: 0.7789\n",
            "Epoch 188/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4901 - accuracy: 0.7778\n",
            "Epoch 189/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.7778\n",
            "Epoch 190/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.7767\n",
            "Epoch 191/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4893 - accuracy: 0.7800\n",
            "Epoch 192/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7767\n",
            "Epoch 193/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4877 - accuracy: 0.7834\n",
            "Epoch 194/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4888 - accuracy: 0.7767\n",
            "Epoch 195/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4868 - accuracy: 0.7868\n",
            "Epoch 196/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4861 - accuracy: 0.7800\n",
            "Epoch 197/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7800\n",
            "Epoch 198/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.7823\n",
            "Epoch 199/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7811\n",
            "Epoch 200/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.7811\n",
            "Epoch 201/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7789\n",
            "Epoch 202/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7845\n",
            "Epoch 203/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7879\n",
            "Epoch 204/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7811\n",
            "Epoch 205/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7823\n",
            "Epoch 206/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7834\n",
            "Epoch 207/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7845\n",
            "Epoch 208/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7868\n",
            "Epoch 209/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7856\n",
            "Epoch 210/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4799 - accuracy: 0.7901\n",
            "Epoch 211/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7811\n",
            "Epoch 212/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7868\n",
            "Epoch 213/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7845\n",
            "Epoch 214/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.7924\n",
            "Epoch 215/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7845\n",
            "Epoch 216/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7845\n",
            "Epoch 217/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7868\n",
            "Epoch 218/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7856\n",
            "Epoch 219/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.7991\n",
            "Epoch 220/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7890\n",
            "Epoch 221/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7879\n",
            "Epoch 222/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7868\n",
            "Epoch 223/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7901\n",
            "Epoch 224/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7879\n",
            "Epoch 225/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7856\n",
            "Epoch 226/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7868\n",
            "Epoch 227/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7901\n",
            "Epoch 228/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.7879\n",
            "Epoch 229/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7890\n",
            "Epoch 230/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7856\n",
            "Epoch 231/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7868\n",
            "Epoch 232/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7845\n",
            "Epoch 233/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7834\n",
            "Epoch 234/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7946\n",
            "Epoch 235/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7811\n",
            "Epoch 236/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7890\n",
            "Epoch 237/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7879\n",
            "Epoch 238/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7834\n",
            "Epoch 239/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7868\n",
            "Epoch 240/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.7868\n",
            "Epoch 241/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.7845\n",
            "Epoch 242/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.7845\n",
            "Epoch 243/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.7800\n",
            "Epoch 244/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.7901\n",
            "Epoch 245/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.7845\n",
            "Epoch 246/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7845\n",
            "Epoch 247/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7856\n",
            "Epoch 248/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.7912\n",
            "Epoch 249/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7879\n",
            "Epoch 250/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7856\n",
            "Epoch 251/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7901\n",
            "Epoch 252/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7868\n",
            "Epoch 253/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7868\n",
            "Epoch 254/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7834\n",
            "Epoch 255/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7912\n",
            "Epoch 256/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7868\n",
            "Epoch 257/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7868\n",
            "Epoch 258/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7890\n",
            "Epoch 259/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7946\n",
            "Epoch 260/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7901\n",
            "Epoch 261/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7912\n",
            "Epoch 262/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7924\n",
            "Epoch 263/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4647 - accuracy: 0.7924\n",
            "Epoch 264/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.7845\n",
            "Epoch 265/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7868\n",
            "Epoch 266/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7935\n",
            "Epoch 267/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4645 - accuracy: 0.7856\n",
            "Epoch 268/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.7901\n",
            "Epoch 269/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7935\n",
            "Epoch 270/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7924\n",
            "Epoch 271/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4636 - accuracy: 0.7845\n",
            "Epoch 272/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7946\n",
            "Epoch 273/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7924\n",
            "Epoch 274/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7935\n",
            "Epoch 275/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7856\n",
            "Epoch 276/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7912\n",
            "Epoch 277/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7924\n",
            "Epoch 278/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.7879\n",
            "Epoch 279/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7868\n",
            "Epoch 280/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7890\n",
            "Epoch 281/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7879\n",
            "Epoch 282/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7834\n",
            "Epoch 283/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7901\n",
            "Epoch 284/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.7879\n",
            "Epoch 285/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4623 - accuracy: 0.7890\n",
            "Epoch 286/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7856\n",
            "Epoch 287/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7856\n",
            "Epoch 288/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7912\n",
            "Epoch 289/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7811\n",
            "Epoch 290/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7912\n",
            "Epoch 291/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7868\n",
            "Epoch 292/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7912\n",
            "Epoch 293/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4602 - accuracy: 0.7856\n",
            "Epoch 294/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7868\n",
            "Epoch 295/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7868\n",
            "Epoch 296/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7890\n",
            "Epoch 297/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7912\n",
            "Epoch 298/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7834\n",
            "Epoch 299/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7890\n",
            "Epoch 300/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.7890\n",
            "Epoch 301/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7856\n",
            "Epoch 302/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7845\n",
            "Epoch 303/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7823\n",
            "Epoch 304/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7890\n",
            "Epoch 305/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7890\n",
            "Epoch 306/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7890\n",
            "Epoch 307/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4578 - accuracy: 0.7879\n",
            "Epoch 308/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7912\n",
            "Epoch 309/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4624 - accuracy: 0.7879\n",
            "Epoch 310/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7856\n",
            "Epoch 311/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7868\n",
            "Epoch 312/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7890\n",
            "Epoch 313/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7879\n",
            "Epoch 314/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7879\n",
            "Epoch 315/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7868\n",
            "Epoch 316/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7879\n",
            "Epoch 317/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7924\n",
            "Epoch 318/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7890\n",
            "Epoch 319/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4576 - accuracy: 0.7901\n",
            "Epoch 320/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7845\n",
            "Epoch 321/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7890\n",
            "Epoch 322/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4568 - accuracy: 0.7901\n",
            "Epoch 323/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7879\n",
            "Epoch 324/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4576 - accuracy: 0.7924\n",
            "Epoch 325/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7879\n",
            "Epoch 326/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7879\n",
            "Epoch 327/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4551 - accuracy: 0.7890\n",
            "Epoch 328/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7901\n",
            "Epoch 329/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7879\n",
            "Epoch 330/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4547 - accuracy: 0.7901\n",
            "Epoch 331/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7912\n",
            "Epoch 332/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7912\n",
            "Epoch 333/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7912\n",
            "Epoch 334/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7901\n",
            "Epoch 335/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7890\n",
            "Epoch 336/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7890\n",
            "Epoch 337/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7868\n",
            "Epoch 338/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7823\n",
            "Epoch 339/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4539 - accuracy: 0.7879\n",
            "Epoch 340/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7912\n",
            "Epoch 341/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7924\n",
            "Epoch 342/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7901\n",
            "Epoch 343/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7834\n",
            "Epoch 344/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7879\n",
            "Epoch 345/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7935\n",
            "Epoch 346/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7890\n",
            "Epoch 347/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7890\n",
            "Epoch 348/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7924\n",
            "Epoch 349/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7834\n",
            "Epoch 350/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7890\n",
            "Epoch 351/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7879\n",
            "Epoch 352/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7890\n",
            "Epoch 353/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7901\n",
            "Epoch 354/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7901\n",
            "Epoch 355/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7834\n",
            "Epoch 356/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7935\n",
            "Epoch 357/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7868\n",
            "Epoch 358/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4523 - accuracy: 0.7901\n",
            "Epoch 359/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.7912\n",
            "Epoch 360/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.7879\n",
            "Epoch 361/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.7890\n",
            "Epoch 362/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4518 - accuracy: 0.7879\n",
            "Epoch 363/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7868\n",
            "Epoch 364/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7901\n",
            "Epoch 365/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7912\n",
            "Epoch 366/600\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4504 - accuracy: 0.7868\n",
            "Epoch 367/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7912\n",
            "Epoch 368/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7901\n",
            "Epoch 369/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7901\n",
            "Epoch 370/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7924\n",
            "Epoch 371/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7901\n",
            "Epoch 372/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7890\n",
            "Epoch 373/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7901\n",
            "Epoch 374/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7912\n",
            "Epoch 375/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7879\n",
            "Epoch 376/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7957\n",
            "Epoch 377/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7935\n",
            "Epoch 378/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7935\n",
            "Epoch 379/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7935\n",
            "Epoch 380/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7901\n",
            "Epoch 381/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7912\n",
            "Epoch 382/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7834\n",
            "Epoch 383/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7912\n",
            "Epoch 384/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7890\n",
            "Epoch 385/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7901\n",
            "Epoch 386/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7912\n",
            "Epoch 387/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7868\n",
            "Epoch 388/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7890\n",
            "Epoch 389/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7845\n",
            "Epoch 390/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7879\n",
            "Epoch 391/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7924\n",
            "Epoch 392/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4492 - accuracy: 0.7901\n",
            "Epoch 393/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.7912\n",
            "Epoch 394/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7879\n",
            "Epoch 395/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7879\n",
            "Epoch 396/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7957\n",
            "Epoch 397/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7946\n",
            "Epoch 398/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7890\n",
            "Epoch 399/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.7924\n",
            "Epoch 400/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7935\n",
            "Epoch 401/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7901\n",
            "Epoch 402/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.7924\n",
            "Epoch 403/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.7856\n",
            "Epoch 404/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7901\n",
            "Epoch 405/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7946\n",
            "Epoch 406/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7924\n",
            "Epoch 407/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7879\n",
            "Epoch 408/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7935\n",
            "Epoch 409/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7890\n",
            "Epoch 410/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7912\n",
            "Epoch 411/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7924\n",
            "Epoch 412/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7879\n",
            "Epoch 413/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7845\n",
            "Epoch 414/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7957\n",
            "Epoch 415/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7924\n",
            "Epoch 416/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7935\n",
            "Epoch 417/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7924\n",
            "Epoch 418/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7845\n",
            "Epoch 419/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7935\n",
            "Epoch 420/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7912\n",
            "Epoch 421/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7935\n",
            "Epoch 422/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7957\n",
            "Epoch 423/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7924\n",
            "Epoch 424/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7946\n",
            "Epoch 425/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7924\n",
            "Epoch 426/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7935\n",
            "Epoch 427/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7879\n",
            "Epoch 428/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7946\n",
            "Epoch 429/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7946\n",
            "Epoch 430/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7969\n",
            "Epoch 431/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7879\n",
            "Epoch 432/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7901\n",
            "Epoch 433/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7901\n",
            "Epoch 434/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7912\n",
            "Epoch 435/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7912\n",
            "Epoch 436/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7935\n",
            "Epoch 437/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7935\n",
            "Epoch 438/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7901\n",
            "Epoch 439/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7946\n",
            "Epoch 440/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7901\n",
            "Epoch 441/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7946\n",
            "Epoch 442/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7935\n",
            "Epoch 443/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7946\n",
            "Epoch 444/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7924\n",
            "Epoch 445/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7957\n",
            "Epoch 446/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7879\n",
            "Epoch 447/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.8025\n",
            "Epoch 448/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7980\n",
            "Epoch 449/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7924\n",
            "Epoch 450/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7969\n",
            "Epoch 451/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7924\n",
            "Epoch 452/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7935\n",
            "Epoch 453/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7924\n",
            "Epoch 454/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.7969\n",
            "Epoch 455/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7924\n",
            "Epoch 456/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7924\n",
            "Epoch 457/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7924\n",
            "Epoch 458/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7980\n",
            "Epoch 459/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.7946\n",
            "Epoch 460/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7935\n",
            "Epoch 461/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7957\n",
            "Epoch 462/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7946\n",
            "Epoch 463/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7924\n",
            "Epoch 464/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7980\n",
            "Epoch 465/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7901\n",
            "Epoch 466/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7912\n",
            "Epoch 467/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7957\n",
            "Epoch 468/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.7957\n",
            "Epoch 469/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7957\n",
            "Epoch 470/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7957\n",
            "Epoch 471/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7969\n",
            "Epoch 472/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7957\n",
            "Epoch 473/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7946\n",
            "Epoch 474/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7991\n",
            "Epoch 475/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7935\n",
            "Epoch 476/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7912\n",
            "Epoch 477/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7935\n",
            "Epoch 478/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7946\n",
            "Epoch 479/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7946\n",
            "Epoch 480/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7969\n",
            "Epoch 481/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.8036\n",
            "Epoch 482/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.7935\n",
            "Epoch 483/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7969\n",
            "Epoch 484/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7957\n",
            "Epoch 485/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7957\n",
            "Epoch 486/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.7946\n",
            "Epoch 487/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7946\n",
            "Epoch 488/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7946\n",
            "Epoch 489/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.8047\n",
            "Epoch 490/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.8002\n",
            "Epoch 491/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7946\n",
            "Epoch 492/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.8025\n",
            "Epoch 493/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7946\n",
            "Epoch 494/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7991\n",
            "Epoch 495/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7957\n",
            "Epoch 496/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7946\n",
            "Epoch 497/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7969\n",
            "Epoch 498/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7969\n",
            "Epoch 499/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.8002\n",
            "Epoch 500/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7969\n",
            "Epoch 501/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7980\n",
            "Epoch 502/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7935\n",
            "Epoch 503/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.8013\n",
            "Epoch 504/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7969\n",
            "Epoch 505/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7991\n",
            "Epoch 506/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.8002\n",
            "Epoch 507/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7901\n",
            "Epoch 508/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7969\n",
            "Epoch 509/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.7969\n",
            "Epoch 510/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.8025\n",
            "Epoch 511/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.8013\n",
            "Epoch 512/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.8025\n",
            "Epoch 513/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7946\n",
            "Epoch 514/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.8036\n",
            "Epoch 515/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7946\n",
            "Epoch 516/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.7969\n",
            "Epoch 517/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7969\n",
            "Epoch 518/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.8013\n",
            "Epoch 519/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.8025\n",
            "Epoch 520/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.8002\n",
            "Epoch 521/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.8013\n",
            "Epoch 522/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.8036\n",
            "Epoch 523/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7991\n",
            "Epoch 524/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.8025\n",
            "Epoch 525/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.8002\n",
            "Epoch 526/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.8025\n",
            "Epoch 527/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7969\n",
            "Epoch 528/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.8036\n",
            "Epoch 529/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.8013\n",
            "Epoch 530/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.8002\n",
            "Epoch 531/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.8002\n",
            "Epoch 532/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.8002\n",
            "Epoch 533/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.8058\n",
            "Epoch 534/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.8025\n",
            "Epoch 535/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7890\n",
            "Epoch 536/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.8058\n",
            "Epoch 537/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7991\n",
            "Epoch 538/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.8047\n",
            "Epoch 539/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.8036\n",
            "Epoch 540/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.7991\n",
            "Epoch 541/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7969\n",
            "Epoch 542/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.8002\n",
            "Epoch 543/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7969\n",
            "Epoch 544/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.8047\n",
            "Epoch 545/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.7969\n",
            "Epoch 546/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7969\n",
            "Epoch 547/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7980\n",
            "Epoch 548/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.8002\n",
            "Epoch 549/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.8081\n",
            "Epoch 550/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.8013\n",
            "Epoch 551/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.8013\n",
            "Epoch 552/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.8013\n",
            "Epoch 553/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.8002\n",
            "Epoch 554/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7991\n",
            "Epoch 555/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.8025\n",
            "Epoch 556/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.8058\n",
            "Epoch 557/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.8002\n",
            "Epoch 558/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.8025\n",
            "Epoch 559/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.8058\n",
            "Epoch 560/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.8013\n",
            "Epoch 561/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.8002\n",
            "Epoch 562/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7991\n",
            "Epoch 563/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.8047\n",
            "Epoch 564/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.8025\n",
            "Epoch 565/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.8013\n",
            "Epoch 566/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7991\n",
            "Epoch 567/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.8002\n",
            "Epoch 568/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.7991\n",
            "Epoch 569/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.8070\n",
            "Epoch 570/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.8013\n",
            "Epoch 571/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.8036\n",
            "Epoch 572/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.8036\n",
            "Epoch 573/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.8025\n",
            "Epoch 574/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7991\n",
            "Epoch 575/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.8013\n",
            "Epoch 576/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.8036\n",
            "Epoch 577/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.8047\n",
            "Epoch 578/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.8036\n",
            "Epoch 579/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7991\n",
            "Epoch 580/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.8036\n",
            "Epoch 581/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.8025\n",
            "Epoch 582/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.8002\n",
            "Epoch 583/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7957\n",
            "Epoch 584/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.8036\n",
            "Epoch 585/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.8036\n",
            "Epoch 586/600\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.8025\n",
            "Epoch 587/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.8013\n",
            "Epoch 588/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.8036\n",
            "Epoch 589/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.8058\n",
            "Epoch 590/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.8036\n",
            "Epoch 591/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.8036\n",
            "Epoch 592/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.8047\n",
            "Epoch 593/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7991\n",
            "Epoch 594/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.8047\n",
            "Epoch 595/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.8036\n",
            "Epoch 596/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.8013\n",
            "Epoch 597/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.8036\n",
            "Epoch 598/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.8025\n",
            "Epoch 599/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.8047\n",
            "Epoch 600/600\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.8025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "ezBkDiuaiLxX",
        "outputId": "7be24d0c-c85c-45f6-88c3-795bc7cb182e"
      },
      "source": [
        "plt.plot(output.history['loss'],color='red')\n",
        "plt.plot(output.history['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f1011595ed0>]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sgwW45IjVvg"
      },
      "source": [
        "test_data = pd.read_csv('/content/test.csv')\n",
        "Survived_data = pd.read_csv('/content/gender_submission.csv')\n",
        "# Survived_data.head()\n",
        "#process\n",
        "test_data = test_data.replace(['female','male'],[0, 1])\n",
        "test_data = test_data.replace(['S','C','Q'],[0, 1, 2])\n",
        "test_data=test_data.fillna(0)\n",
        "\n",
        "X_test = test_data[['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']]\n",
        "Y_test = Survived_data[['Survived']]\n",
        "X_test = np.array(X_test)\n",
        "Y_test = np.array(Y_test) \n",
        "\n",
        "from keras import layers\n",
        "layer = layers.Normalization()\n",
        "layer.adapt(X_test)\n",
        "X_test = layer(X_test).numpy()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQ7nTt76lQ_K",
        "outputId": "c5b43c4b-a6e7-49a1-a6de-ce9562d9f3d1"
      },
      "source": [
        "acc=model.evaluate(X_test,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1196 - accuracy: 0.9617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-rgqRfgwwMd",
        "outputId": "eadf515d-bd96-4da6-cacf-66b8a6e09f45"
      },
      "source": [
        "jack=np.array([3,0,30,2,1,72.0,1])\n",
        "jack=jack.reshape(1,7)\n",
        "y_pred=model.predict(jack)\n",
        "prid=np.argmax(y_pred)\n",
        "print('predict :',prid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predict : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgm2g1I8-nio",
        "outputId": "bb64428d-2cf6-4920-d933-733ace51930a"
      },
      "source": [
        "#KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "l_2=[]\n",
        "for k in range(5):\n",
        "  knc=KNeighborsClassifier(n_neighbors=5)\n",
        "  knc.fit(X_train,Y_train)\n",
        "  pred=knc.predict(X_test)\n",
        "  test_score=knc.score(X_test,Y_test)\n",
        "  l_2.append(test_score)\n",
        "print(np.max(l_2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6363636363636364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  import sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef7P9sdpCs8b",
        "outputId": "864bd320-3894-44f1-857c-834b8a7e59ea"
      },
      "source": [
        "#adaline \n",
        "from numpy.linalg import inv\n",
        "class AdalineClassifier:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def fit(self,x_train,y_train):\n",
        "        self.w=np.matmul(inv(np.matmul(x_train.T,x_train)),np.matmul(x_train.T,y_train))\n",
        "    def predict(self,x_test):\n",
        "        y_pred=np.matmul(x_test,self.w)\n",
        "        y_pred=np.round(y_pred)\n",
        "        return y_pred\n",
        "    def evaluate_mae(self,x_test,y_test):\n",
        "        y_pred=np.matmul(x_test,self.w)\n",
        "        y_pred[y_pred>0.5]=1\n",
        "        y_pred[y_pred <= 0.5]=0\n",
        "        evaluatation=(y_pred==y_test).sum()/len(y_test)\n",
        "        return evaluatation \n",
        "\n",
        "# x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.5)\n",
        "model=AdalineClassifier()\n",
        "model.fit(X_train,Y_train)\n",
        "y_pred=model.predict(X_test)\n",
        "accuracy = model.evaluate_mae(X_test, Y_test)\n",
        "print('accuracy :',accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.8110047846889952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsn42PzqEbNj",
        "outputId": "554f80e5-5e75-45a4-ed8a-73d945adab8c"
      },
      "source": [
        "#perceptron\n",
        "def fit(X_train,Y_train):\n",
        "    lr=0.001\n",
        "    epochs=500\n",
        "    N=X_train.shape[0]\n",
        "    \n",
        "    W = np.random.rand(7,1)\n",
        "    b = np.random.rand(1, 1)\n",
        "\n",
        "\n",
        "    for i in range(epochs):\n",
        "        errors = []\n",
        "\n",
        "        for n in range(N):\n",
        "\n",
        "            y_pred = np.matmul(X_train[n:n+1],W)+b\n",
        "            e = np.subtract(Y_train[n], y_pred)\n",
        "\n",
        "            Y_pred = np.matmul(X_train, W) + b\n",
        "            error = np.mean(np.abs(Y_train - Y_pred))\n",
        "            errors.append(error)\n",
        "\n",
        "            #update\n",
        "            W = W + lr*X_train[n:n+1,:].T* e\n",
        "            b = b + lr * e\n",
        "\n",
        "    np.save('Weight.npy',W)\n",
        "    np.save('baias.npy',b)\n",
        " \n",
        "    return W,b\n",
        "\n",
        "def predict(X_test):\n",
        "    w=np.load('Weight.npy')\n",
        "    b=np.load('baias.npy')\n",
        "    y_pred=np.matmul(X_test,w)+b\n",
        "    return y_pred\n",
        "\n",
        "def evaluate(x_test,y_test):\n",
        "    w=np.load('Weight.npy')\n",
        "    b=np.load('baias.npy')\n",
        "    y_pred = np.matmul(X_test, w) + b   \n",
        "    y_pred[y_pred>0.5]=1\n",
        "    y_pred[y_pred <= 0.5]=0 \n",
        "    evaluatation=(y_pred == y_test).sum()/len(y_test)\n",
        "    return evaluatation\n",
        "\n",
        "from keras import layers\n",
        "layer = layers.Normalization()\n",
        "layer.adapt(X_train)\n",
        "X_train = layer(X_train).numpy()\n",
        "m,b = fit(X_train,Y_train)\n",
        "y_pred=predict(X_test)\n",
        "accuracy = evaluate(X_test, Y_test)\n",
        "print('accuracy', accuracy)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.9784688995215312\n"
          ]
        }
      ]
    }
  ]
}